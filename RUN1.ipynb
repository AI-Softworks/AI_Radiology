{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "GPU is available.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check for GPU availability\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tqdm\n",
      "Version: 4.66.5\n",
      "Summary: Fast, Extensible Progress Meter\n",
      "Home-page: https://tqdm.github.io\n",
      "Author: \n",
      "Author-email: \n",
      "License: MPL-2.0 AND MIT\n",
      "Location: c:\\users\\zap\\.conda\\envs\\tf_cuda\\lib\\site-packages\n",
      "Requires: colorama\n",
      "Required-by: \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip show tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tqdm import tqdm  # For the progress bar\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class ChestXrayDataset:\n",
    "    def __new__(cls, csv_file, root_dir, transform=None):\n",
    "        cls.root_dir = root_dir  # Store root_dir as class attribute\n",
    "        cls.transform = transform  # Store transform as class attribute\n",
    "\n",
    "        labels_frame = pd.read_csv(csv_file)\n",
    "        img_names = labels_frame.iloc[:, 0].values\n",
    "        labels = labels_frame.iloc[:, 1].values\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((img_names, labels))\n",
    "        \n",
    "        # Map img_name and label using the _load_image_and_label function\n",
    "        dataset = dataset.map(lambda img_name, label: tf.py_function(\n",
    "            func=cls._load_image_and_label, \n",
    "            inp=[img_name, label],  # Only pass img_name and label as tensors\n",
    "            Tout=(tf.float32, tf.float32)\n",
    "        ), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_image_and_label(img_name, label):\n",
    "        try:\n",
    "            img_name = img_name.numpy().decode(\"utf-8\")\n",
    "            label = label.numpy().decode(\"utf-8\")\n",
    "            \n",
    "            img_path = ChestXrayDataset.find_image(img_name)\n",
    "\n",
    "            if img_path is None:\n",
    "                image = np.zeros((256, 256, 3), dtype=np.uint8)  # Return a default 256x256 black image\n",
    "                one_hot_label = np.zeros(14, dtype=np.float32)  # Return a default label of zeros\n",
    "            else:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                image = np.array(image)\n",
    "\n",
    "                # Apply the transformation if provided\n",
    "                if ChestXrayDataset.transform:\n",
    "                    image = ChestXrayDataset.transform(image)\n",
    "\n",
    "                # Convert label to one-hot encoding\n",
    "                labels = label.split('|')\n",
    "                one_hot_label = np.array([1 if c in labels else 0 for c in ChestXrayDataset.get_classes()], dtype=np.float32)\n",
    "\n",
    "            return image, one_hot_label\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_name}: {e}\")\n",
    "            image = np.zeros((256, 256, 3), dtype=np.uint8)  # Safe fallback image\n",
    "            one_hot_label = np.zeros(14, dtype=np.float32)  # Safe fallback label\n",
    "            return image, one_hot_label\n",
    "\n",
    "    @staticmethod\n",
    "    def find_image(img_name):\n",
    "        for i in range(1, 3):\n",
    "            folder = f'images_{i:03d}'\n",
    "            img_path = os.path.join(ChestXrayDataset.root_dir, folder, 'images', img_name)\n",
    "            if os.path.exists(img_path):\n",
    "                return img_path\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_classes():\n",
    "        return ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema',\n",
    "                'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_thickening',\n",
    "                'Cardiomegaly', 'Nodule Mass', 'Hernia', 'No Finding']\n",
    "\n",
    "# Set up the CNN model using TensorFlow/Keras\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(image):\n",
    "    image = tf.image.resize(image, (256, 256))\n",
    "    image = (image / 255.0) * 2 - 1  # Normalize to [-1, 1]\n",
    "    return image\n",
    "\n",
    "csv_file = './MED_IMG_DATA/NIH_Chest_X-rays/Data_Entry_2017.csv'\n",
    "data_dir = './MED_IMG_DATA/NIH_Chest_X-rays/images_001'\n",
    "batch_size = 16\n",
    "\n",
    "# Load dataset and split into train/validation sets\n",
    "dataset = ChestXrayDataset(csv_file, data_dir, transform=preprocess)\n",
    "\n",
    "# 80% train, 20% validation split\n",
    "dataset_list = list(dataset)  # Force dataset evaluation\n",
    "train_size = int(0.8 * len(dataset_list))\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(dataset_list[:train_size]).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(dataset_list[train_size:]).batch(batch_size)\n",
    "\n",
    "# Compile and train the model\n",
    "input_shape = (256, 256, 3)\n",
    "num_classes = 14\n",
    "model = create_model(input_shape, num_classes)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Custom training loop with progress display using tqdm\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Training loop\n",
    "    prog_bar = tqdm(train_dataset, total=len(train_dataset), desc=\"Training\", unit=\"batch\")\n",
    "    for step, (images, labels) in enumerate(prog_bar):\n",
    "        loss_value, accuracy_value = model.train_on_batch(images, labels)\n",
    "        \n",
    "        prog_bar.set_postfix({\"loss\": loss_value, \"accuracy\": accuracy_value})\n",
    "\n",
    "    # Validation loop\n",
    "    print(\"\\nValidating...\")\n",
    "    prog_bar_val = tqdm(val_dataset, total=len(val_dataset), desc=\"Validation\", unit=\"batch\")\n",
    "    val_loss, val_acc = 0, 0\n",
    "    for step, (images, labels) in enumerate(prog_bar_val):\n",
    "        val_loss_value, val_acc_value = model.test_on_batch(images, labels)\n",
    "        val_loss += val_loss_value\n",
    "        val_acc += val_acc_value\n",
    "        prog_bar_val.set_postfix({\"val_loss\": val_loss_value, \"val_accuracy\": val_acc_value})\n",
    "    \n",
    "    # Average validation metrics across the validation set\n",
    "    avg_val_loss = val_loss / len(val_dataset)\n",
    "    avg_val_acc = val_acc / len(val_dataset)\n",
    "    print(f\"\\nEpoch {epoch+1} Summary: Val Loss: {avg_val_loss:.4f}, Val Accuracy: {avg_val_acc:.4f}\")\n",
    "\n",
    "print('Finished Training')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_CUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
